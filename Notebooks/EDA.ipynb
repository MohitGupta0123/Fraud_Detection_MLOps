{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a3ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Standard Library --------------------\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import itertools\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------------------- Core Scientific Libraries --------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------- Visualization --------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------- Statistical Analysis --------------------\n",
    "from scipy.stats import skew, shapiro, kurtosis, chi2_contingency, f_oneway, kruskal\n",
    "\n",
    "# -------------------- Scikit-learn Core --------------------\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# -------------------- Gradient Boosting --------------------\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------- Imbalanced Learning --------------------\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# -------------------- Experiment Tracking (MLflow) --------------------\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# -------------------- Model Persistence --------------------\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7cf4636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>Category</th>\n",
       "      <th>isWeekend</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>paypal</td>\n",
       "      <td>28.204861</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>4.921318</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>food</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAgeDays  numItems  localTime paymentMethod  paymentMethodAgeDays  \\\n",
       "0              29         1   4.745402        paypal             28.204861   \n",
       "1             725         1   4.742303   storecredit              0.000000   \n",
       "2             845         1   4.921318    creditcard              0.000000   \n",
       "3             503         1   4.886641    creditcard              0.000000   \n",
       "4            2000         1   5.040929    creditcard              0.000000   \n",
       "\n",
       "      Category  isWeekend  label  \n",
       "0     shopping        0.0      0  \n",
       "1  electronics        0.0      0  \n",
       "2         food        1.0      0  \n",
       "3  electronics        1.0      0  \n",
       "4     shopping        0.0      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Asus\\Downloads\\Fraud_MLOps_Project\\Data\\payment_fraud.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8bcf5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(df, ignore_duplicate=False)\n",
    "# d.open_browser()\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ab95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDA:\n",
    "    def __init__(self, df, report_path=\"eda_results\", outlier_method=\"iqr\", threshold=1.5):\n",
    "        \"\"\"\n",
    "        outlier_method: 'iqr' or 'zscore'\n",
    "        threshold: For IQR -> multiplier (1.5), for Z-Score -> sigma (3)\n",
    "        \"\"\"\n",
    "        self.df = df.copy()  # Read-only\n",
    "        self.report_path = report_path\n",
    "        self.outlier_method = outlier_method\n",
    "        self.threshold = threshold\n",
    "        self.target_col = None\n",
    "\n",
    "        # Folder structure\n",
    "        folders = [\n",
    "            \"missing_data\", \"cardinality\", \"numerical_analysis\", \"categorical_analysis\",\n",
    "            \"relationships\", \"outliers\", \"distribution_shape\", \"target_analysis\",\n",
    "            \"advanced_relationships\"\n",
    "        ]\n",
    "        for folder in folders:\n",
    "            os.makedirs(os.path.join(report_path, folder), exist_ok=True)\n",
    "\n",
    "    # ----------------- Helper Functions -----------------\n",
    "    def save_text(self, folder, filename, content):\n",
    "        with open(os.path.join(self.report_path, folder, filename), \"w\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "    def set_target(self, target_name=None):\n",
    "        if target_name is None:\n",
    "            target_name = input(\"Enter target column name (or leave blank if none): \").strip()\n",
    "        if target_name and target_name in self.df.columns:\n",
    "            self.target_col = target_name\n",
    "            print(f\"[Info] Target column set to: {self.target_col}\")\n",
    "        else:\n",
    "            self.target_col = None\n",
    "            print(\"[Info] No target column set\")\n",
    "\n",
    "    # ----------------- 1. Missing Data Analysis -----------------\n",
    "    def advanced_missing_data(self):\n",
    "        missing = self.df.isnull().sum()\n",
    "        missing_percent = (missing / len(self.df)) * 100\n",
    "        summary = pd.DataFrame({\"Missing Count\": missing, \"Missing %\": missing_percent})\n",
    "        summary = summary[summary[\"Missing Count\"] > 0].sort_values(by=\"Missing %\", ascending=False)\n",
    "        self.save_text(\"missing_data\", \"missing_summary.txt\", str(summary))\n",
    "\n",
    "        # Heatmap\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(self.df.isnull(), cbar=False)\n",
    "        plt.title(\"Missing Data Heatmap\")\n",
    "        plt.savefig(os.path.join(self.report_path, \"missing_data\", \"missing_heatmap.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # Missing correlation (binary mask correlation)\n",
    "        missing_corr = self.df.isnull().astype(int).corr()\n",
    "        self.save_text(\"missing_data\", \"missing_correlation.txt\", str(missing_corr))\n",
    "\n",
    "        print(\"[Saved] Missing data summary, heatmap & correlation\")\n",
    "\n",
    "    # ----------------- 2. Cardinality Analysis -----------------\n",
    "    def cardinality_analysis(self):\n",
    "        cat_cols = self.df.select_dtypes(exclude=np.number).columns\n",
    "        summary = {}\n",
    "        high_cardinality = []\n",
    "        for col in cat_cols:\n",
    "            count = self.df[col].nunique()\n",
    "            summary[col] = count\n",
    "            if count > 50:  # Arbitrary threshold\n",
    "                high_cardinality.append(col)\n",
    "        text = f\"Cardinality per categorical feature:\\n{summary}\\n\\nHigh cardinality features (>50 unique): {high_cardinality}\"\n",
    "        self.save_text(\"cardinality\", \"cardinality_summary.txt\", text)\n",
    "        print(\"[Saved] Cardinality summary with high-cardinality flags\")\n",
    "\n",
    "    # ----------------- 3. Numerical Feature Relationships -----------------\n",
    "    def numerical_relationships(self):\n",
    "        num_cols = self.df.select_dtypes(include=np.number).columns\n",
    "        if len(num_cols) <= 10 and len(num_cols) > 1:\n",
    "            sns.pairplot(self.df[num_cols].dropna())\n",
    "            plt.savefig(os.path.join(self.report_path, \"relationships\", \"pairplot.png\"))\n",
    "            plt.close()\n",
    "            print(\"[Saved] Pairplot for numerical features\")\n",
    "\n",
    "        # Boxplot of numeric vs categorical target\n",
    "        if self.target_col and self.df[self.target_col].dtype == 'object':\n",
    "            for col in num_cols:\n",
    "                plt.figure(figsize=(6, 4))\n",
    "                sns.boxplot(x=self.df[self.target_col], y=self.df[col])\n",
    "                plt.title(f\"{col} vs {self.target_col} (Boxplot)\")\n",
    "                plt.savefig(os.path.join(self.report_path, \"relationships\", f\"{col}_vs_target_box.png\"))\n",
    "                plt.close()\n",
    "\n",
    "        # Scatterplot vs continuous target\n",
    "        if self.target_col and self.df[self.target_col].dtype != 'object':\n",
    "            for col in num_cols:\n",
    "                if col == self.target_col: continue\n",
    "                plt.figure(figsize=(6, 4))\n",
    "                sns.scatterplot(x=self.df[col], y=self.df[self.target_col])\n",
    "                plt.title(f\"{col} vs {self.target_col}\")\n",
    "                plt.savefig(os.path.join(self.report_path, \"relationships\", f\"{col}_vs_target.png\"))\n",
    "                plt.close()\n",
    "\n",
    "    # ----------------- 4. Categorical Feature Relationships -----------------\n",
    "    def categorical_relationships(self):\n",
    "        cat_cols = self.df.select_dtypes(exclude=np.number).columns\n",
    "        chi_summary = []\n",
    "        for col1, col2 in itertools.combinations(cat_cols, 2):\n",
    "            table = pd.crosstab(self.df[col1], self.df[col2])\n",
    "            chi2, p, _, _ = chi2_contingency(table)\n",
    "            chi_summary.append(f\"{col1} vs {col2} -> p={p:.4f}\")\n",
    "        self.save_text(\"relationships\", \"categorical_chi2.txt\", \"\\n\".join(chi_summary))\n",
    "\n",
    "        # Cramér’s V\n",
    "        cramer_results = []\n",
    "        for col1, col2 in itertools.combinations(cat_cols, 2):\n",
    "            table = pd.crosstab(self.df[col1], self.df[col2])\n",
    "            chi2 = chi2_contingency(table)[0]\n",
    "            n = table.sum().sum()\n",
    "            phi2 = chi2 / n\n",
    "            r, k = table.shape\n",
    "            phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "            rcorr = r - ((r-1)**2)/(n-1)\n",
    "            kcorr = k - ((k-1)**2)/(n-1)\n",
    "            cramer_v = np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "            cramer_results.append(f\"{col1} vs {col2} -> Cramér's V={cramer_v:.4f}\")\n",
    "        self.save_text(\"relationships\", \"categorical_cramers_v.txt\", \"\\n\".join(cramer_results))\n",
    "        print(\"[Saved] Chi-square and Cramér's V results for categorical features\")\n",
    "\n",
    "    # ----------------- 5. Feature Importance (Mutual Information) -----------------\n",
    "    def feature_importance(self):\n",
    "        if self.target_col:\n",
    "            X = self.df.drop(columns=[self.target_col]).select_dtypes(include=np.number).fillna(0)\n",
    "            y = self.df[self.target_col]\n",
    "            if y.dtype == 'object':\n",
    "                y = y.astype('category').cat.codes\n",
    "                scores = mutual_info_classif(X, y)\n",
    "            else:\n",
    "                scores = mutual_info_regression(X, y)\n",
    "            mi_scores = pd.Series(scores, index=X.columns).sort_values(ascending=False)\n",
    "            self.save_text(\"relationships\", \"mutual_information.txt\", str(mi_scores))\n",
    "            print(\"[Saved] Mutual Information scores\")\n",
    "\n",
    "    # ----------------- 6. Target Advanced Analysis -----------------\n",
    "    def target_advanced(self):\n",
    "        if self.target_col:\n",
    "            # Class imbalance\n",
    "            if self.df[self.target_col].dtype == 'object':\n",
    "                counts = self.df[self.target_col].value_counts(normalize=True) * 100\n",
    "                self.save_text(\"target_analysis\", \"class_imbalance.txt\", str(counts))\n",
    "            # Target mean per categorical\n",
    "            cat_cols = self.df.select_dtypes(exclude=np.number).columns\n",
    "            for col in cat_cols:\n",
    "                if col != self.target_col:\n",
    "                    mean_vals = self.df.groupby(col)[self.target_col].mean(numeric_only=True)\n",
    "                    self.save_text(\"target_analysis\", f\"{col}_target_mean.txt\", str(mean_vals))\n",
    "            print(\"[Saved] Target distribution & mean analysis per category\")\n",
    "\n",
    "    # ----------------- 7. Correlation Beyond Pearson -----------------\n",
    "    def advanced_correlations(self):\n",
    "        num_df = self.df.select_dtypes(include=np.number)\n",
    "        if num_df.shape[1] > 1:\n",
    "            # Compute correlations\n",
    "            spearman_corr = num_df.corr(method='spearman')\n",
    "            kendall_corr = num_df.corr(method='kendall')\n",
    "\n",
    "            # Save correlation matrices\n",
    "            self.save_text(\"advanced_relationships\", \"spearman_corr.txt\", str(spearman_corr))\n",
    "            self.save_text(\"advanced_relationships\", \"kendall_corr.txt\", str(kendall_corr))\n",
    "\n",
    "            # Clean correlation matrix for clustering (replace NaN with 0)\n",
    "            corr_matrix = num_df.corr().fillna(0)\n",
    "\n",
    "            try:\n",
    "                sns.clustermap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "                plt.savefig(os.path.join(self.report_path, \"advanced_relationships\", \"clustered_corr_heatmap.png\"))\n",
    "                plt.close()\n",
    "                print(\"[Saved] Spearman, Kendall correlations & clustered heatmap\")\n",
    "            except ValueError:\n",
    "                print(\"[Warning] Could not generate clustered heatmap (NaNs/Infs in data even after fill).\")\n",
    "        else:\n",
    "            print(\"[Info] Not enough numerical columns for advanced correlation analysis.\")\n",
    "\n",
    "    # ----------------- 8. Outlier Profiling -----------------\n",
    "    def outlier_profiling(self):\n",
    "        num_cols = self.df.select_dtypes(include=np.number).columns\n",
    "        results = []\n",
    "        for col in num_cols:\n",
    "            Q1, Q3 = self.df[col].quantile([0.25, 0.75])\n",
    "            IQR = Q3 - Q1\n",
    "            lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "            outliers = self.df[(self.df[col] < lower) | (self.df[col] > upper)]\n",
    "            results.append(f\"{col}: {len(outliers)} outliers ({(len(outliers)/len(self.df))*100:.2f}%)\")\n",
    "            # Boxplot\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            sns.boxplot(x=self.df[col])\n",
    "            plt.title(f\"Boxplot: {col}\")\n",
    "            plt.savefig(os.path.join(self.report_path, \"outliers\", f\"box_{col}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # Multivariate outliers using Isolation Forest\n",
    "        iso = IsolationForest(contamination=0.05)\n",
    "        preds = iso.fit_predict(self.df[num_cols].fillna(0))\n",
    "        outlier_count = np.sum(preds == -1)\n",
    "        results.append(f\"Multivariate Outliers (IsolationForest): {outlier_count}\")\n",
    "\n",
    "        self.save_text(\"outliers\", \"outlier_profile.txt\", \"\\n\".join(results))\n",
    "        print(\"[Saved] Outlier profiles & multivariate outliers\")\n",
    "\n",
    "    # ----------------- 9. Distribution Shape -----------------\n",
    "    def distribution_shape(self):\n",
    "        num_cols = self.df.select_dtypes(include=np.number).columns\n",
    "        results = []\n",
    "        for col in num_cols:\n",
    "            data = self.df[col].dropna()\n",
    "            skew_val = skew(data)\n",
    "            kurt_val = kurtosis(data)\n",
    "            stat, p = shapiro(data.sample(min(5000, len(data))))\n",
    "            results.append(f\"{col}: Skew={skew_val:.2f}, Kurtosis={kurt_val:.2f}, Shapiro p={p:.4f}\")\n",
    "            # Histogram\n",
    "            sns.histplot(data, kde=True)\n",
    "            plt.title(f\"Distribution: {col}\")\n",
    "            plt.savefig(os.path.join(self.report_path, \"distribution_shape\", f\"dist_{col}.png\"))\n",
    "            plt.close()\n",
    "        self.save_text(\"distribution_shape\", \"distribution_stats.txt\", \"\\n\".join(results))\n",
    "        print(\"[Saved] Skewness, kurtosis & normality plots\")\n",
    "\n",
    "    # ----------------- 10. Dataset Integrity -----------------\n",
    "    def integrity_checks(self):\n",
    "        results = []\n",
    "        # Constant features\n",
    "        constant_cols = [col for col in self.df.columns if self.df[col].nunique() == 1]\n",
    "        if constant_cols:\n",
    "            results.append(f\"Constant columns: {constant_cols}\")\n",
    "\n",
    "        # Highly correlated pairs\n",
    "        num_df = self.df.select_dtypes(include=np.number)\n",
    "        corr_matrix = num_df.corr().abs()\n",
    "        high_corr = np.where((corr_matrix > 0.9) & (corr_matrix < 1))\n",
    "        high_corr_pairs = [(num_df.columns[i], num_df.columns[j]) for i, j in zip(*high_corr)]\n",
    "        if high_corr_pairs:\n",
    "            results.append(f\"Highly correlated pairs: {high_corr_pairs}\")\n",
    "\n",
    "        # Duplicate features\n",
    "        duplicate_features = []\n",
    "        for col1, col2 in itertools.combinations(self.df.columns, 2):\n",
    "            if self.df[col1].equals(self.df[col2]):\n",
    "                duplicate_features.append((col1, col2))\n",
    "        if duplicate_features:\n",
    "            results.append(f\"Duplicate features: {duplicate_features}\")\n",
    "\n",
    "        self.save_text(\"relationships\", \"integrity_checks.txt\", \"\\n\".join(results) if results else \"No issues found\")\n",
    "        print(\"[Saved] Integrity checks\")\n",
    "\n",
    "    # ----------------- Numerical & Categorical Plots -----------------\n",
    "    def numerical_analysis(self):\n",
    "        num_cols = self.df.select_dtypes(include=np.number).columns\n",
    "        for col in num_cols:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            sns.histplot(self.df[col].dropna(), kde=True)\n",
    "            plt.title(f\"Distribution of {col}\")\n",
    "            plt.savefig(os.path.join(self.report_path, \"numerical_analysis\", f\"hist_{col}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            sns.boxplot(x=self.df[col].dropna())\n",
    "            plt.title(f\"Boxplot of {col}\")\n",
    "            plt.savefig(os.path.join(self.report_path, \"numerical_analysis\", f\"box_{col}.png\"))\n",
    "            plt.close()\n",
    "        print(\"[Saved] Numerical feature plots\")\n",
    "\n",
    "    def categorical_analysis(self):\n",
    "        cat_cols = self.df.select_dtypes(exclude=np.number).columns\n",
    "        for col in cat_cols:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            sns.countplot(y=self.df[col], order=self.df[col].value_counts().index)\n",
    "            plt.title(f\"Count Plot of {col}\")\n",
    "            plt.savefig(os.path.join(self.report_path, \"categorical_analysis\", f\"count_{col}.png\"))\n",
    "            plt.close()\n",
    "        print(\"[Saved] Categorical feature plots\")\n",
    "    \n",
    "    def duplicate_rows_detail(self):\n",
    "        duplicates = self.df[self.df.duplicated()]\n",
    "        if not duplicates.empty:\n",
    "            duplicates.to_csv(os.path.join(self.report_path, \"relationships\", \"duplicate_rows.csv\"), index=False)\n",
    "            print(f\"[Saved] Detailed duplicate rows ({len(duplicates)} rows)\")\n",
    "        else:\n",
    "            print(\"[Info] No duplicate rows found\")\n",
    "    \n",
    "    def data_imbalance_heatmap(self):\n",
    "        if self.target_col and self.df[self.target_col].dtype == 'object':\n",
    "            counts = self.df[self.target_col].value_counts(normalize=True) * 100\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            sns.heatmap(counts.to_frame(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "            plt.title(f\"Class Imbalance Heatmap for {self.target_col}\")\n",
    "            plt.savefig(os.path.join(self.report_path, \"target_analysis\", \"imbalance_heatmap.png\"))\n",
    "            plt.close()\n",
    "            print(\"[Saved] Target imbalance heatmap\")\n",
    "        else:\n",
    "            print(\"[Info] Target imbalance heatmap skipped (target not categorical)\")\n",
    "\n",
    "    def scaling_transformation_suggestions(self):\n",
    "        num_cols = self.df.select_dtypes(include=np.number).columns\n",
    "        suggestions = []\n",
    "\n",
    "        for col in num_cols:\n",
    "            data = self.df[col].dropna()\n",
    "            if len(data) == 0: \n",
    "                continue\n",
    "\n",
    "            # Skewness check\n",
    "            skew_val = skew(data)\n",
    "            suggestion = f\"{col}: Skew={skew_val:.2f} -> \"\n",
    "            if abs(skew_val) > 1:\n",
    "                suggestion += \"Highly skewed; consider Log or Box-Cox transform\"\n",
    "            elif abs(skew_val) > 0.5:\n",
    "                suggestion += \"Moderately skewed; consider mild transform\"\n",
    "            else:\n",
    "                suggestion += \"Fairly symmetric\"\n",
    "\n",
    "            # Scaling suggestion\n",
    "            if (data.max() - data.min()) > 1000:\n",
    "                suggestion += \" | Suggest MinMax Scaling (large range)\"\n",
    "            else:\n",
    "                suggestion += \" | Suggest Standard Scaling (normal range)\"\n",
    "\n",
    "            suggestions.append(suggestion)\n",
    "\n",
    "        self.save_text(\"numerical_analysis\", \"scaling_transformation_suggestions.txt\", \"\\n\".join(suggestions))\n",
    "        print(\"[Saved] Scaling and transformation suggestions\")\n",
    "\n",
    "    # ----------------- Run All -----------------\n",
    "    def run_all(self, target_name=None):\n",
    "        print(\"===== Starting EDA =====\")\n",
    "        self.set_target(target_name)\n",
    "        self.advanced_missing_data()\n",
    "        self.cardinality_analysis()\n",
    "        self.numerical_analysis()\n",
    "        self.categorical_analysis()\n",
    "        self.numerical_relationships()\n",
    "        self.categorical_relationships()\n",
    "        self.feature_importance()\n",
    "        self.target_advanced()\n",
    "        self.advanced_correlations()\n",
    "        self.outlier_profiling()\n",
    "        self.distribution_shape()\n",
    "        self.integrity_checks()\n",
    "        self.duplicate_rows_detail()\n",
    "        self.data_imbalance_heatmap()\n",
    "        self.scaling_transformation_suggestions()\n",
    "\n",
    "        summary = \"EDA Completed.\\nCheck folders for:\\n\"\n",
    "        summary += \"\\n\".join([\n",
    "            \"- missing_data\", \"- cardinality\", \"- numerical_analysis\",\n",
    "            \"- categorical_analysis\", \"- relationships\", \"- outliers\",\n",
    "            \"- distribution_shape\", \"- target_analysis\", \"- advanced_relationships\"\n",
    "        ])\n",
    "        self.save_text(\"\", \"summary.txt\", summary)\n",
    "        print(f\"\\nEDA completed! Full report at '{self.report_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ccb18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Starting EDA =====\n",
      "[Info] Target column set to: label\n",
      "[Saved] Missing data summary, heatmap & correlation\n",
      "[Saved] Cardinality summary with high-cardinality flags\n",
      "[Saved] Numerical feature plots\n",
      "[Saved] Categorical feature plots\n",
      "[Saved] Pairplot for numerical features\n",
      "[Saved] Chi-square and Cramér's V results for categorical features\n",
      "[Saved] Mutual Information scores\n",
      "[Saved] Target distribution & mean analysis per category\n",
      "[Saved] Spearman, Kendall correlations & clustered heatmap\n",
      "[Saved] Outlier profiles & multivariate outliers\n",
      "[Saved] Skewness, kurtosis & normality plots\n",
      "[Saved] Integrity checks\n",
      "[Saved] Detailed duplicate rows (3033 rows)\n",
      "[Info] Target imbalance heatmap skipped (target not categorical)\n",
      "[Saved] Scaling and transformation suggestions\n",
      "\n",
      "EDA completed! Full report at 'Advanced_EDA_Results'\n"
     ]
    }
   ],
   "source": [
    "eda = EDA(df, report_path=\"Advanced_EDA_Results\", outlier_method=\"zscore\", threshold=3)\n",
    "eda.run_all(target_name=\"label\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6d0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eda_collage(report_path=\"eda_results\", output_file=\"eda_summary_collage.png\", cols=3, image_size=(600, 400)):\n",
    "    \"\"\"\n",
    "    Combine all .png images from EDA folders into one collage\n",
    "    \"\"\"\n",
    "    # Find all images recursively\n",
    "    image_paths = glob.glob(os.path.join(report_path, \"**\", \"*.png\"), recursive=True)\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(\"No images found to combine.\")\n",
    "        return\n",
    "\n",
    "    # Resize all images to uniform size\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = img.resize(image_size)  # Resize for uniformity\n",
    "        images.append(img)\n",
    "\n",
    "    # Determine grid size\n",
    "    total_images = len(images)\n",
    "    rows = math.ceil(total_images / cols)\n",
    "    width = cols * image_size[0]\n",
    "    height = rows * image_size[1]\n",
    "\n",
    "    # Create blank canvas\n",
    "    collage = Image.new(\"RGB\", (width, height), color=(255, 255, 255))\n",
    "\n",
    "    # Paste images in grid\n",
    "    for idx, img in enumerate(images):\n",
    "        x = (idx % cols) * image_size[0]\n",
    "        y = (idx // cols) * image_size[1]\n",
    "        collage.paste(img, (x, y))\n",
    "\n",
    "    # Save collage\n",
    "    collage.save(os.path.join(report_path, output_file))\n",
    "    print(f\"[Saved] Collage created at: {os.path.join(report_path, output_file)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40be9212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] Collage created at: Advanced_EDA_Results\\eda_summary_collage.png\n"
     ]
    }
   ],
   "source": [
    "create_eda_collage(report_path=\"Advanced_EDA_Results\", cols=4, image_size=(500, 350))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe4a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_summary(report_path=\"eda_results\", output_file=\"eda_text_summary.txt\"):\n",
    "    \"\"\"\n",
    "    Combine all EDA text results into one summary file\n",
    "    \"\"\"\n",
    "    text_paths = glob.glob(os.path.join(report_path, \"**\", \"*.txt\"), recursive=True)\n",
    "    summary_content = []\n",
    "\n",
    "    for path in sorted(text_paths):\n",
    "        # Skip the final summary itself to avoid duplication\n",
    "        if output_file in path:\n",
    "            continue\n",
    "        relative_path = os.path.relpath(path, report_path)\n",
    "        summary_content.append(f\"\\n===== {relative_path} =====\\n\")\n",
    "        with open(path, \"r\") as f:\n",
    "            summary_content.append(f.read())\n",
    "\n",
    "    with open(os.path.join(report_path, output_file), \"w\") as f:\n",
    "        f.write(\"\\n\".join(summary_content))\n",
    "\n",
    "    print(f\"[Saved] Combined text summary at: {os.path.join(report_path, output_file)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d005e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] Combined text summary at: Advanced_EDA_Results\\eda_text_summary.txt\n"
     ]
    }
   ],
   "source": [
    "create_text_summary(report_path=\"Advanced_EDA_Results\", output_file=\"eda_text_summary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae6d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:./mlruns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6762ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom feature engineering transformer.\n",
    "    Controlled via steps_to_apply list:\n",
    "    - 'feature_engineering': enable feature engineering\n",
    "    - 'interaction': Category x PaymentMethod\n",
    "    - 'ratio': paymentMethodAgeDays / accountAgeDays\n",
    "    - 'binning': bins for accountAgeDays\n",
    "    - 'time_feature': bins for localTime\n",
    "    \"\"\"\n",
    "    def __init__(self, steps_to_apply=None):\n",
    "        self.steps_to_apply = steps_to_apply or []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Skip entire feature engineering if 'feature_engineering' not in steps\n",
    "        if 'feature_engineering' not in self.steps_to_apply:\n",
    "            return X\n",
    "\n",
    "        # Interaction Feature\n",
    "        if 'interaction' in self.steps_to_apply:\n",
    "            if 'Category' in X.columns and 'paymentMethod' in X.columns:\n",
    "                X['Category_Payment'] = X['Category'] + '_' + X['paymentMethod']\n",
    "\n",
    "        # Ratio Feature\n",
    "        if 'ratio' in self.steps_to_apply:\n",
    "            if 'paymentMethodAgeDays' in X.columns and 'accountAgeDays' in X.columns:\n",
    "                X['payment_account_ratio'] = X['paymentMethodAgeDays'] / (X['accountAgeDays'] + 1)\n",
    "\n",
    "        # Binning Feature\n",
    "        if 'binning' in self.steps_to_apply:\n",
    "            if 'accountAgeDays' in X.columns:\n",
    "                X['account_age_bin'] = pd.cut(\n",
    "                    X['accountAgeDays'],\n",
    "                    bins=[0, 90, 730, 2000],\n",
    "                    labels=['new', 'medium', 'old']\n",
    "                )\n",
    "\n",
    "        # Time-of-day Feature\n",
    "        if 'time_feature' in self.steps_to_apply:\n",
    "            if 'localTime' in X.columns:\n",
    "                bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "                labels = ['early_morning', 'morning', 'afternoon', 'evening', 'night']\n",
    "                X['time_of_day'] = pd.cut(X['localTime'], bins=bins, labels=labels)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92e4541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Log Transformer -----------\n",
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.log1p(np.array(X, dtype=float))\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return input_features\n",
    "\n",
    "\n",
    "# ----------- Preprocessing Class -----------\n",
    "class Preprocessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features, skewed_features, symmetric_features,\n",
    "                 steps_to_apply=None, random_state=42):\n",
    "        \"\"\"\n",
    "        Preprocessing pipeline (impute, encoding, log, scaling).\n",
    "        SMOTE/ADASYN will be applied separately after this step.\n",
    "        \"\"\"\n",
    "        self.categorical_features = categorical_features\n",
    "        self.skewed_features = skewed_features\n",
    "        self.symmetric_features = symmetric_features\n",
    "        self.steps_to_apply = steps_to_apply or []\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.preprocessor = None  # ColumnTransformer will be built dynamically\n",
    "\n",
    "    def _build_pipeline(self):\n",
    "        \"\"\"Build column transformer dynamically based on steps_to_apply.\"\"\"\n",
    "\n",
    "        # ----- Categorical pipeline -----\n",
    "        cat_steps = []\n",
    "        if 'impute' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            cat_steps.append(('imputer', SimpleImputer(strategy='most_frequent')))\n",
    "        if 'encoding' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            cat_steps.append(('encoder', OneHotEncoder(handle_unknown='ignore', drop='first')))\n",
    "        cat_pipeline = Pipeline(cat_steps) if cat_steps else 'passthrough'\n",
    "\n",
    "        # ----- Skewed numerical pipeline -----\n",
    "        skewed_steps = []\n",
    "        if 'impute' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            skewed_steps.append(('imputer', SimpleImputer(strategy='median')))\n",
    "        if 'log_transform' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            skewed_steps.append(('log', LogTransformer()))\n",
    "        if 'encoding' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:  # scaling numeric\n",
    "            skewed_steps.append(('scaler', StandardScaler()))\n",
    "        skewed_pipeline = Pipeline(skewed_steps) if skewed_steps else 'passthrough'\n",
    "\n",
    "        # ----- Symmetric numerical pipeline -----\n",
    "        sym_steps = []\n",
    "        if 'impute' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            sym_steps.append(('imputer', SimpleImputer(strategy='median')))\n",
    "        if 'encoding' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            sym_steps.append(('scaler', MinMaxScaler()))\n",
    "        sym_pipeline = Pipeline(sym_steps) if sym_steps else 'passthrough'\n",
    "\n",
    "        # ----- Combine all pipelines -----\n",
    "        self.preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', cat_pipeline, self.categorical_features),\n",
    "                ('skew', skewed_pipeline, self.skewed_features),\n",
    "                ('sym', sym_pipeline, self.symmetric_features)\n",
    "            ],\n",
    "            remainder='drop'\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._build_pipeline()\n",
    "        self.preprocessor.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform WITHOUT resampling (pure preprocessing).\"\"\"\n",
    "        return self.preprocessor.transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit and transform WITHOUT resampling (SMOTE will be handled outside).\"\"\"\n",
    "        self._build_pipeline()\n",
    "        return self.preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70385a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- FRAUD PIPELINE CLASS -------------------------\n",
    "class FraudPipeline:\n",
    "    # ----- Step mappings -----\n",
    "    FEATURE_ENG_SUBSTEPS = ['interaction', 'ratio', 'binning', 'time_feature']\n",
    "    PREPROCESS_SUBSTEPS = ['encoding', 'impute', 'log_transform', 'smote']\n",
    "    \n",
    "    def __init__(self, steps_to_apply=None, model=None, test_size=0.2,\n",
    "                 random_state=42, resample_method=\"smote\", experiment_name=\"FraudDetection\"):\n",
    "        self.steps_to_apply = self.expand_steps(steps_to_apply)\n",
    "        self.model = model or RandomForestClassifier(class_weight='balanced', random_state=random_state)\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.resample_method = resample_method\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "        # Pipeline placeholder\n",
    "        self.pipeline = None\n",
    "\n",
    "        # Feature groups\n",
    "        self.categorical = ['Category', 'paymentMethod', 'isWeekend']\n",
    "        self.skewed = ['numItems', 'localTime', 'paymentMethodAgeDays']\n",
    "        self.symmetric = ['accountAgeDays']\n",
    "        self.target = 'label'\n",
    "\n",
    "        # Initialize MLflow experiment\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    # ------------------------- STEP EXPANSION -------------------------\n",
    "    def expand_steps(self, steps_to_apply):\n",
    "        \"\"\"Strict parent-substep logic with full-step auto expansion.\"\"\"\n",
    "        steps = set(steps_to_apply or [])\n",
    "\n",
    "        # ---------- Feature Engineering ----------\n",
    "        fe_substeps = steps.intersection(self.FEATURE_ENG_SUBSTEPS)\n",
    "\n",
    "        if fe_substeps and 'feature_engineering' not in steps:\n",
    "            raise ValueError(\n",
    "                f\"Feature engineering sub-steps {fe_substeps} provided without 'feature_engineering' parent step.\"\n",
    "            )\n",
    "\n",
    "        if 'feature_engineering' in steps:\n",
    "            if fe_substeps:\n",
    "                steps = steps  # Only chosen sub-steps\n",
    "            else:\n",
    "                steps.update(self.FEATURE_ENG_SUBSTEPS)  # Apply all sub-steps\n",
    "\n",
    "        # ---------- Preprocessing ----------\n",
    "        pre_substeps = steps.intersection(self.PREPROCESS_SUBSTEPS)\n",
    "\n",
    "        if pre_substeps and 'preprocessing' not in steps:\n",
    "            raise ValueError(\n",
    "                f\"Preprocessing sub-steps {pre_substeps} provided without 'preprocessing' parent step.\"\n",
    "            )\n",
    "\n",
    "        if 'preprocessing' in steps:\n",
    "            if pre_substeps:\n",
    "                steps = steps\n",
    "            else:\n",
    "                steps.update(self.PREPROCESS_SUBSTEPS)  # Apply all preprocessing steps\n",
    "\n",
    "        return list(steps)\n",
    "\n",
    "    # ------------------------- TRAIN -------------------------\n",
    "    def train(self, df):\n",
    "        \"\"\"Fit full pipeline with no data leakage and log experiment metadata.\"\"\"\n",
    "\n",
    "        # --- Split ---\n",
    "        X = df.drop(columns=[self.target])\n",
    "        y = df[self.target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, stratify=y, test_size=self.test_size, random_state=self.random_state, shuffle=True\n",
    "        )\n",
    "\n",
    "        # # --- Remove duplicates from training set only ---\n",
    "        # train_data = pd.concat([X_train, y_train], axis=1)\n",
    "        # train_data = train_data.drop_duplicates()\n",
    "        # X_train = train_data.drop(columns=[self.target])\n",
    "        # y_train = train_data[self.target]\n",
    "        # print(len(train_data[train_data.duplicated()]))\n",
    "\n",
    "        # --- Feature Engineering Step ---\n",
    "        feature_engineer = FeatureEngineering(steps_to_apply=self.steps_to_apply) \\\n",
    "            if any(s in self.steps_to_apply for s in self.FEATURE_ENG_SUBSTEPS) else 'passthrough'\n",
    "\n",
    "        # --- Preprocessing Step ---\n",
    "        preprocessor = Preprocessing(\n",
    "            self.categorical, self.skewed, self.symmetric,\n",
    "            steps_to_apply=self.steps_to_apply,\n",
    "            random_state=self.random_state\n",
    "        ) if any(s in self.steps_to_apply for s in self.PREPROCESS_SUBSTEPS) else 'passthrough'\n",
    "\n",
    "        # --- Build pipeline (no resampling in pipeline) ---\n",
    "        self.pipeline = ImbPipeline([\n",
    "            ('feature_engineering', feature_engineer),\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('model', self.model)\n",
    "        ])\n",
    "\n",
    "        # --- Transform Train/Test separately (no leakage) ---\n",
    "        X_train_transformed = self.pipeline[:-1].fit_transform(X_train, y_train)\n",
    "        X_test_transformed = self.pipeline[:-1].transform(X_test)\n",
    "\n",
    "        # --- Apply SMOTE/ADASYN only on Train ---\n",
    "        if 'smote' in self.steps_to_apply:\n",
    "            if self.resample_method == \"smote\":\n",
    "                sampler = SMOTE(random_state=self.random_state, sampling_strategy='minority', k_neighbors=5)\n",
    "            elif self.resample_method == \"adasyn\":\n",
    "                sampler = ADASYN(random_state=self.random_state, sampling_strategy='minority', n_neighbors=5)\n",
    "            else:\n",
    "                raise ValueError(\"resample_method must be 'smote' or 'adasyn'\")\n",
    "\n",
    "            X_train_transformed, y_train = sampler.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "        # --- Train Model ---\n",
    "        if 'model_training' in self.steps_to_apply:\n",
    "            with mlflow.start_run(run_name=f\"{type(self.model).__name__}_run\"):\n",
    "                # -------- Log Parameters --------\n",
    "                mlflow.log_param(\"steps_to_apply\", self.steps_to_apply)\n",
    "                mlflow.log_param(\"resample_method\", self.resample_method)\n",
    "                mlflow.log_param(\"test_size\", self.test_size)\n",
    "                mlflow.log_param(\"model\", type(self.model).__name__)\n",
    "                mlflow.log_param(\"categorical_features\", self.categorical)\n",
    "                mlflow.log_param(\"skewed_features\", self.skewed)\n",
    "                mlflow.log_param(\"symmetric_features\", self.symmetric)\n",
    "\n",
    "                # -------- Train and Evaluate --------\n",
    "                self.model.fit(X_train_transformed, y_train)\n",
    "                y_train_pred = self.model.predict(X_train_transformed)\n",
    "                y_test_pred = self.model.predict(X_test_transformed)\n",
    "\n",
    "                # Log metrics\n",
    "                train_metrics = self._calculate_metrics(y_train, y_train_pred, prefix=\"train\")\n",
    "                test_metrics = self._calculate_metrics(y_test, y_test_pred, prefix=\"test\")\n",
    "                self._log_metrics(train_metrics)\n",
    "                self._log_metrics(test_metrics)\n",
    "\n",
    "                # Confusion matrix artifact (PNG)\n",
    "                cm = confusion_matrix(y_test, y_test_pred)\n",
    "                fig, ax = plt.subplots(figsize=(6, 4))\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "                ax.set_title('Confusion Matrix')\n",
    "                ax.set_xlabel('Predicted')\n",
    "                ax.set_ylabel('Actual')\n",
    "\n",
    "                cm_png_path = \"artifacts/confusion_matrix.png\"\n",
    "                os.makedirs(\"artifacts\", exist_ok=True)\n",
    "                plt.savefig(cm_png_path, bbox_inches='tight')\n",
    "                plt.close(fig)\n",
    "\n",
    "                # Log confusion matrix image to MLflow\n",
    "                mlflow.log_artifact(cm_png_path, \"confusion_matrix\")\n",
    "\n",
    "                # Log data distribution\n",
    "                class_dist = y.value_counts(normalize=True).to_dict()\n",
    "                mlflow.log_param(\"class_distribution\", json.dumps(class_dist))\n",
    "\n",
    "                # Log signature\n",
    "                signature = infer_signature(X_train_transformed, self.model.predict(X_train_transformed))\n",
    "                mlflow.sklearn.log_model(self.pipeline, name=\"fraud_pipeline\", signature=signature)\n",
    "\n",
    "                # Save pipeline\n",
    "                joblib.dump(self.pipeline, \"artifacts/fraud_pipeline.pkl\")\n",
    "                mlflow.log_artifacts(\"artifacts\")\n",
    "\n",
    "        return self.pipeline, X_train_transformed, y_train, X_test_transformed, y_test\n",
    "\n",
    "    # ------------------------- PREPROCESS -------------------------\n",
    "    def preprocess(self, df):\n",
    "        if not self.pipeline:\n",
    "            raise ValueError(\"Pipeline not trained. Train first or load fitted pipeline.\")\n",
    "        return self.pipeline[:-1].transform(df)\n",
    "\n",
    "    # ------------------------- PREDICT -------------------------\n",
    "    def predict(self, df):\n",
    "        if not self.pipeline:\n",
    "            raise ValueError(\"Pipeline not trained. Train first or load fitted pipeline.\")\n",
    "        return self.pipeline.predict(df)\n",
    "\n",
    "\n",
    "    # ------------------------- METRICS UTILS -------------------------\n",
    "    def _calculate_metrics(self, y_true, y_pred, prefix=\"\"):\n",
    "        return {\n",
    "            f\"{prefix}_accuracy\": accuracy_score(y_true, y_pred),\n",
    "            f\"{prefix}_precision\": precision_score(y_true, y_pred),\n",
    "            f\"{prefix}_recall\": recall_score(y_true, y_pred),\n",
    "            f\"{prefix}_f1\": f1_score(y_true, y_pred)\n",
    "        }\n",
    "\n",
    "    def _log_metrics(self, metrics):\n",
    "        for k, v in metrics.items():\n",
    "            mlflow.log_metric(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3cc677e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (35988, 8)\n",
      "Hold-out data size: (100, 8)\n",
      "Hold-out data size: (100, 8)\n",
      "\n",
      "--- Internal Test Split Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96      7119\n",
      "           1       0.13      1.00      0.23        79\n",
      "\n",
      "    accuracy                           0.92      7198\n",
      "   macro avg       0.56      0.96      0.59      7198\n",
      "weighted avg       0.99      0.92      0.95      7198\n",
      "\n",
      "Internal Test Split Accuracy:  0.9246\n",
      "Internal Test Split Precision: 0.1270\n",
      "Internal Test Split Recall:    1.0000\n",
      "Internal Test Split F1 Score:   0.2254\n",
      "\n",
      "--- Hold-out Set Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        99\n",
      "           1       0.14      1.00      0.25         1\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.57      0.97      0.61       100\n",
      "weighted avg       0.99      0.94      0.96       100\n",
      "\n",
      "Hold-out Set Accuracy:  0.9400\n",
      "Hold-out Set Precision: 0.1429\n",
      "Hold-out Set Recall:    1.0000\n",
      "Hold-out Set F1 Score:   0.2500\n",
      "\n",
      "--- Hold-out Set B Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        99\n",
      "           1       0.11      1.00      0.20         1\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.56      0.96      0.58       100\n",
      "weighted avg       0.99      0.92      0.95       100\n",
      "\n",
      "Hold-out Set B Accuracy:  0.9200\n",
      "Hold-out Set B Precision: 0.1111\n",
      "Hold-out Set B Recall:    1.0000\n",
      "Hold-out Set B F1 Score:   0.2000\n",
      "\n",
      "Pipeline saved as 'fraud_pipeline_deployed.pkl'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>True_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5589</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24727</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predictions  True_Value\n",
       "35999            0           0\n",
       "18192            0           0\n",
       "5589             0           0\n",
       "18168            0           0\n",
       "24727            0           0\n",
       "...            ...         ...\n",
       "25217            0           0\n",
       "8568             0           0\n",
       "7560             0           0\n",
       "28968            0           0\n",
       "5727             1           1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>True_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26114</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13314</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19651</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13654</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9782</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13045</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predictions  True_Value\n",
       "6153             0           0\n",
       "660              0           0\n",
       "26114            0           0\n",
       "35825            0           0\n",
       "13314            0           0\n",
       "...            ...         ...\n",
       "19651            0           0\n",
       "13654            0           0\n",
       "9782             0           0\n",
       "13045            0           0\n",
       "6037             1           1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, dataset_name=\"Evaluation\"):\n",
    "    \"\"\"\n",
    "    Prints and returns classification metrics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True labels.\n",
    "    y_pred : array-like\n",
    "        Predicted labels.\n",
    "    dataset_name : str\n",
    "        Name for the dataset (used in print titles and keys).\n",
    "    \"\"\"\n",
    "    # Print full classification report\n",
    "    print(f\"\\n--- {dataset_name} Classification Report ---\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Compute and print summary metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{dataset_name} Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"{dataset_name} Precision: {precision:.4f}\")\n",
    "    print(f\"{dataset_name} Recall:    {recall:.4f}\")\n",
    "    print(f\"{dataset_name} F1 Score:   {f1:.4f}\")\n",
    "\n",
    "    # Return metrics as a dictionary\n",
    "    return {\n",
    "        f\"{dataset_name}_accuracy\": accuracy,\n",
    "        f\"{dataset_name}_precision\": precision,\n",
    "        f\"{dataset_name}_recall\": recall,\n",
    "        f\"{dataset_name}_f1\": f1,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------- Step 1: Create Hold-out Set -----------------------\n",
    "df_clean = df.drop_duplicates(keep='first')\n",
    "\n",
    "n1, n2 = 99, 1\n",
    "holdout_class_0 = df_clean[df_clean['label'] == 0].sample(n1, random_state=42)\n",
    "holdout_class_1 = df_clean[df_clean['label'] == 1].sample(n2, random_state=42)\n",
    "holdout_df = pd.concat([holdout_class_0, holdout_class_1])\n",
    "\n",
    "train_df = df_clean.drop(holdout_df.index)\n",
    "\n",
    "X_holdout = holdout_df.drop(columns=['label'])\n",
    "y_holdout = holdout_df['label']\n",
    "\n",
    "holdout_class_0_B = train_df[train_df['label'] == 0].sample(n1, random_state=42)\n",
    "holdout_class_1_B = train_df[train_df['label'] == 1].sample(n2, random_state=42)\n",
    "holdout_df_B = pd.concat([holdout_class_0_B, holdout_class_1_B])\n",
    "\n",
    "train_df = train_df.drop(holdout_df_B.index)\n",
    "\n",
    "X_holdout_B = holdout_df_B.drop(columns=['label'])\n",
    "y_holdout_B = holdout_df_B['label']\n",
    "\n",
    "print(f\"Training data size: {train_df.shape}\")\n",
    "print(f\"Hold-out data size: {holdout_df.shape}\")\n",
    "print(f\"Hold-out data size: {holdout_df_B.shape}\")\n",
    "\n",
    "# ----------------------- Step 2: Initialize FraudPipeline -----------------------\n",
    "fp = FraudPipeline(\n",
    "    steps_to_apply=[\n",
    "        'feature_engineering', \n",
    "        # 'interaction', \n",
    "        # 'ratio', \n",
    "        # 'binning', \n",
    "        # 'time_feature',\n",
    "        \n",
    "        'preprocessing', \n",
    "        # 'encoding', \n",
    "        # 'impute', \n",
    "        # 'log_transform', \n",
    "        # 'smote', \n",
    "        \n",
    "        'model_training',\n",
    "    ],\n",
    "    # resample_method='smote',\n",
    "    # model=xgb.XGBClassifier(),\n",
    "    model=LogisticRegression(),\n",
    ")\n",
    "\n",
    "# ----------------------- Step 3: Train Pipeline -----------------------\n",
    "pipeline, X_train, y_train, X_test, y_test = fp.train(train_df)\n",
    "\n",
    "# ----------------------- Step 4: Evaluate on Internal Test Split -----------------------\n",
    "test_predictions = fp.model.predict(X_test)\n",
    "test_metrics = evaluate_model(y_test, test_predictions, dataset_name=\"Internal Test Split\")\n",
    "\n",
    "# ----------------------- Step 5: Evaluate on Hold-out Set -----------------------\n",
    "holdout_predictions = fp.predict(X_holdout)\n",
    "holdout_metrics = evaluate_model(y_holdout, holdout_predictions, dataset_name=\"Hold-out Set\")\n",
    "holdout_predictions_B = fp.predict(X_holdout_B)\n",
    "holdout_metrics_B = evaluate_model(y_holdout_B, holdout_predictions_B, dataset_name=\"Hold-out Set B\")\n",
    "\n",
    "# ----------------------- Step 6: Save Pipeline -----------------------\n",
    "joblib.dump(fp.pipeline, \"fraud_pipeline_deployed.pkl\")\n",
    "print(\"\\nPipeline saved as 'fraud_pipeline_deployed.pkl'\")\n",
    "\n",
    "# ----------------------- Step 7: Load & Predict (Example) -----------------------\n",
    "loaded_pipeline = joblib.load(\"fraud_pipeline_deployed.pkl\")\n",
    "sample_preds = loaded_pipeline.predict(X_holdout)\n",
    "sample_preds_B = loaded_pipeline.predict(X_holdout_B)\n",
    "\n",
    "display(pd.DataFrame({'Predictions': sample_preds, 'True_Value': y_holdout}).head(100))\n",
    "display(pd.DataFrame({'Predictions': sample_preds_B, 'True_Value': y_holdout_B}).head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "958c0d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;feature_engineering&#x27;,\n",
       "                 FeatureEngineering(steps_to_apply=[&#x27;binning&#x27;, &#x27;ratio&#x27;,\n",
       "                                                    &#x27;model_training&#x27;,\n",
       "                                                    &#x27;interaction&#x27;,\n",
       "                                                    &#x27;time_feature&#x27;,\n",
       "                                                    &#x27;preprocessing&#x27;,\n",
       "                                                    &#x27;log_transform&#x27;, &#x27;impute&#x27;,\n",
       "                                                    &#x27;feature_engineering&#x27;,\n",
       "                                                    &#x27;encoding&#x27;, &#x27;smote&#x27;])),\n",
       "                (&#x27;preprocessing&#x27;,\n",
       "                 Preprocessing(categorical_features=[&#x27;Category&#x27;,\n",
       "                                                     &#x27;paymentMethod&#x27;,\n",
       "                                                     &#x27;isWeekend&#x27;],\n",
       "                               skewed_features=[&#x27;numItems&#x27;, &#x27;localTime&#x27;,\n",
       "                                                &#x27;paymentMethodAgeDays&#x27;],\n",
       "                               steps_to_apply=[&#x27;binning&#x27;, &#x27;ratio&#x27;,\n",
       "                                               &#x27;model_training&#x27;, &#x27;interaction&#x27;,\n",
       "                                               &#x27;time_feature&#x27;, &#x27;preprocessing&#x27;,\n",
       "                                               &#x27;log_transform&#x27;, &#x27;impute&#x27;,\n",
       "                                               &#x27;feature_engineering&#x27;,\n",
       "                                               &#x27;encoding&#x27;, &#x27;smote&#x27;],\n",
       "                               symmetric_features=[&#x27;accountAgeDays&#x27;])),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;feature_engineering&#x27;,\n",
       "                 FeatureEngineering(steps_to_apply=[&#x27;binning&#x27;, &#x27;ratio&#x27;,\n",
       "                                                    &#x27;model_training&#x27;,\n",
       "                                                    &#x27;interaction&#x27;,\n",
       "                                                    &#x27;time_feature&#x27;,\n",
       "                                                    &#x27;preprocessing&#x27;,\n",
       "                                                    &#x27;log_transform&#x27;, &#x27;impute&#x27;,\n",
       "                                                    &#x27;feature_engineering&#x27;,\n",
       "                                                    &#x27;encoding&#x27;, &#x27;smote&#x27;])),\n",
       "                (&#x27;preprocessing&#x27;,\n",
       "                 Preprocessing(categorical_features=[&#x27;Category&#x27;,\n",
       "                                                     &#x27;paymentMethod&#x27;,\n",
       "                                                     &#x27;isWeekend&#x27;],\n",
       "                               skewed_features=[&#x27;numItems&#x27;, &#x27;localTime&#x27;,\n",
       "                                                &#x27;paymentMethodAgeDays&#x27;],\n",
       "                               steps_to_apply=[&#x27;binning&#x27;, &#x27;ratio&#x27;,\n",
       "                                               &#x27;model_training&#x27;, &#x27;interaction&#x27;,\n",
       "                                               &#x27;time_feature&#x27;, &#x27;preprocessing&#x27;,\n",
       "                                               &#x27;log_transform&#x27;, &#x27;impute&#x27;,\n",
       "                                               &#x27;feature_engineering&#x27;,\n",
       "                                               &#x27;encoding&#x27;, &#x27;smote&#x27;],\n",
       "                               symmetric_features=[&#x27;accountAgeDays&#x27;])),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>FeatureEngineering</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>FeatureEngineering(steps_to_apply=[&#x27;binning&#x27;, &#x27;ratio&#x27;, &#x27;model_training&#x27;,\n",
       "                                   &#x27;interaction&#x27;, &#x27;time_feature&#x27;,\n",
       "                                   &#x27;preprocessing&#x27;, &#x27;log_transform&#x27;, &#x27;impute&#x27;,\n",
       "                                   &#x27;feature_engineering&#x27;, &#x27;encoding&#x27;, &#x27;smote&#x27;])</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Preprocessing</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Preprocessing(categorical_features=[&#x27;Category&#x27;, &#x27;paymentMethod&#x27;, &#x27;isWeekend&#x27;],\n",
       "              skewed_features=[&#x27;numItems&#x27;, &#x27;localTime&#x27;, &#x27;paymentMethodAgeDays&#x27;],\n",
       "              steps_to_apply=[&#x27;binning&#x27;, &#x27;ratio&#x27;, &#x27;model_training&#x27;,\n",
       "                              &#x27;interaction&#x27;, &#x27;time_feature&#x27;, &#x27;preprocessing&#x27;,\n",
       "                              &#x27;log_transform&#x27;, &#x27;impute&#x27;, &#x27;feature_engineering&#x27;,\n",
       "                              &#x27;encoding&#x27;, &#x27;smote&#x27;],\n",
       "              symmetric_features=[&#x27;accountAgeDays&#x27;])</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('feature_engineering',\n",
       "                 FeatureEngineering(steps_to_apply=['binning', 'ratio',\n",
       "                                                    'model_training',\n",
       "                                                    'interaction',\n",
       "                                                    'time_feature',\n",
       "                                                    'preprocessing',\n",
       "                                                    'log_transform', 'impute',\n",
       "                                                    'feature_engineering',\n",
       "                                                    'encoding', 'smote'])),\n",
       "                ('preprocessing',\n",
       "                 Preprocessing(categorical_features=['Category',\n",
       "                                                     'paymentMethod',\n",
       "                                                     'isWeekend'],\n",
       "                               skewed_features=['numItems', 'localTime',\n",
       "                                                'paymentMethodAgeDays'],\n",
       "                               steps_to_apply=['binning', 'ratio',\n",
       "                                               'model_training', 'interaction',\n",
       "                                               'time_feature', 'preprocessing',\n",
       "                                               'log_transform', 'impute',\n",
       "                                               'feature_engineering',\n",
       "                                               'encoding', 'smote'],\n",
       "                               symmetric_features=['accountAgeDays'])),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the serialized pipeline\n",
    "loaded_pipeline = joblib.load(\"artifacts/fraud_pipeline.pkl\")\n",
    "# loaded_pipeline = joblib.load(\"fraud_pipeline_deployed.pkl\")\n",
    "\n",
    "# Use it directly to predict\n",
    "sample_data = df.drop(['label'], axis=1)   # Or new unseen data\n",
    "predictions = loaded_pipeline.predict(sample_data)\n",
    "\n",
    "print(predictions)\n",
    "loaded_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8918be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "229c7e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns BEFORE Feature Engineering:\n",
      "['accountAgeDays', 'numItems', 'localTime', 'paymentMethod', 'paymentMethodAgeDays', 'Category', 'isWeekend']\n",
      "\n",
      "Columns AFTER Feature Engineering:\n",
      "['accountAgeDays', 'numItems', 'localTime', 'paymentMethod', 'paymentMethodAgeDays', 'Category', 'isWeekend', 'Category_Payment', 'payment_account_ratio', 'account_age_bin', 'time_of_day']\n",
      "\n",
      "Newly added columns: {'time_of_day', 'Category_Payment', 'account_age_bin', 'payment_account_ratio'}\n",
      "\n",
      "Sample transformed data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>Category</th>\n",
       "      <th>isWeekend</th>\n",
       "      <th>Category_Payment</th>\n",
       "      <th>payment_account_ratio</th>\n",
       "      <th>account_age_bin</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>paypal</td>\n",
       "      <td>28.204861</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shopping_paypal</td>\n",
       "      <td>0.940162</td>\n",
       "      <td>new</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>electronics_storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>medium</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>4.921318</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>food</td>\n",
       "      <td>1.0</td>\n",
       "      <td>food_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>old</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>electronics_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>medium</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shopping_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>old</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAgeDays  numItems  localTime paymentMethod  paymentMethodAgeDays  \\\n",
       "0              29         1   4.745402        paypal             28.204861   \n",
       "1             725         1   4.742303   storecredit              0.000000   \n",
       "2             845         1   4.921318    creditcard              0.000000   \n",
       "3             503         1   4.886641    creditcard              0.000000   \n",
       "4            2000         1   5.040929    creditcard              0.000000   \n",
       "\n",
       "      Category  isWeekend         Category_Payment  payment_account_ratio  \\\n",
       "0     shopping        0.0          shopping_paypal               0.940162   \n",
       "1  electronics        0.0  electronics_storecredit               0.000000   \n",
       "2         food        1.0          food_creditcard               0.000000   \n",
       "3  electronics        1.0   electronics_creditcard               0.000000   \n",
       "4     shopping        0.0      shopping_creditcard               0.000000   \n",
       "\n",
       "  account_age_bin time_of_day  \n",
       "0             new       night  \n",
       "1          medium       night  \n",
       "2             old       night  \n",
       "3          medium       night  \n",
       "4             old       night  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Split your dataset ---\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Instantiate FeatureEngineering\n",
    "fe = FeatureEngineering(steps_to_apply=['feature_engineering', 'interaction', 'ratio', 'binning', 'time_feature'])\n",
    "\n",
    "# BEFORE: Inspect original columns\n",
    "print(\"Columns BEFORE Feature Engineering:\")\n",
    "print(list(X.columns))\n",
    "\n",
    "# Apply Feature Engineering\n",
    "X_transformed = fe.fit_transform(X)\n",
    "\n",
    "# AFTER: Inspect new columns\n",
    "print(\"\\nColumns AFTER Feature Engineering:\")\n",
    "print(list(X_transformed.columns))\n",
    "\n",
    "# Compare column difference\n",
    "added_columns = set(X_transformed.columns) - set(X.columns)\n",
    "print(\"\\nNewly added columns:\", added_columns)\n",
    "\n",
    "# Show head of transformed data\n",
    "print(\"\\nSample transformed data:\")\n",
    "display(X_transformed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53c75aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Columns: ['accountAgeDays', 'numItems', 'localTime', 'paymentMethod', 'paymentMethodAgeDays', 'Category', 'isWeekend']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>Category</th>\n",
       "      <th>isWeekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>paypal</td>\n",
       "      <td>28.204861</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>4.921318</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>food</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAgeDays  numItems  localTime paymentMethod  paymentMethodAgeDays  \\\n",
       "0              29         1   4.745402        paypal             28.204861   \n",
       "1             725         1   4.742303   storecredit              0.000000   \n",
       "2             845         1   4.921318    creditcard              0.000000   \n",
       "3             503         1   4.886641    creditcard              0.000000   \n",
       "4            2000         1   5.040929    creditcard              0.000000   \n",
       "\n",
       "      Category  isWeekend  \n",
       "0     shopping        0.0  \n",
       "1  electronics        0.0  \n",
       "2         food        1.0  \n",
       "3  electronics        1.0  \n",
       "4     shopping        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Shape: (39221, 9)\n",
      "Transformed Columns (after encoding, scaling, log):\n",
      "['Category_food', 'Category_shopping', 'paymentMethod_paypal', 'paymentMethod_storecredit', 'isWeekend_1.0', 'numItems', 'localTime', 'paymentMethodAgeDays', 'accountAgeDays']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_food</th>\n",
       "      <th>Category_shopping</th>\n",
       "      <th>paymentMethod_paypal</th>\n",
       "      <th>paymentMethod_storecredit</th>\n",
       "      <th>isWeekend_1.0</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>accountAgeDays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.028772</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.014007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.362181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.421745</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.422211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.345213</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.251126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.682328</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_food  Category_shopping  paymentMethod_paypal  \\\n",
       "0            0.0                1.0                   1.0   \n",
       "1            0.0                0.0                   0.0   \n",
       "2            1.0                0.0                   0.0   \n",
       "3            0.0                0.0                   0.0   \n",
       "4            0.0                1.0                   0.0   \n",
       "\n",
       "   paymentMethod_storecredit  isWeekend_1.0  numItems  localTime  \\\n",
       "0                        0.0            0.0 -0.189142   0.028772   \n",
       "1                        1.0            0.0 -0.189142   0.021742   \n",
       "2                        0.0            1.0 -0.189142   0.421745   \n",
       "3                        0.0            1.0 -0.189142   0.345213   \n",
       "4                        0.0            0.0 -0.189142   0.682328   \n",
       "\n",
       "   paymentMethodAgeDays  accountAgeDays  \n",
       "0              0.557839        0.014007  \n",
       "1             -0.775564        0.362181  \n",
       "2             -0.775564        0.422211  \n",
       "3             -0.775564        0.251126  \n",
       "4             -0.775564        1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_feature_names_from_column_transformer(column_transformer):\n",
    "    output_features = []\n",
    "    for name, pipe, features in column_transformer.transformers_:\n",
    "        if name != 'remainder':\n",
    "            if hasattr(pipe, 'named_steps'):\n",
    "                last_step = list(pipe.named_steps.values())[-1]\n",
    "                if hasattr(last_step, 'get_feature_names_out'):\n",
    "                    feature_names = last_step.get_feature_names_out(features)\n",
    "                else:\n",
    "                    feature_names = features\n",
    "            else:\n",
    "                feature_names = features\n",
    "            output_features.extend(feature_names)\n",
    "        else:\n",
    "            output_features.extend(features)  # passthrough features\n",
    "    return output_features\n",
    "\n",
    "# Assume you have X (original features) and Preprocessing object\n",
    "pre = Preprocessing(\n",
    "    categorical_features=['Category', 'paymentMethod', 'isWeekend'],\n",
    "    skewed_features=['numItems', 'localTime', 'paymentMethodAgeDays'],\n",
    "    symmetric_features=['accountAgeDays'],\n",
    "    steps_to_apply=['preprocessing']  # full preprocessing\n",
    ")\n",
    "\n",
    "# BEFORE: original data\n",
    "print(\"Original Columns:\", X.columns.tolist())\n",
    "display(X.head())\n",
    "\n",
    "# Fit + transform\n",
    "X_transformed = pre.fit_transform(X)\n",
    "\n",
    "# Get transformed column names\n",
    "transformed_cols = get_feature_names_from_column_transformer(pre.preprocessor)\n",
    "\n",
    "# AFTER: transformed data\n",
    "print(\"\\nTransformed Shape:\", X_transformed.shape)\n",
    "print(\"Transformed Columns (after encoding, scaling, log):\")\n",
    "print(transformed_cols)\n",
    "\n",
    "# Convert transformed array to DataFrame for easy inspection\n",
    "X_transformed_df = pd.DataFrame(X_transformed, columns=transformed_cols)\n",
    "\n",
    "# Show first few rows\n",
    "display(X_transformed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb197a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed columns:\n",
      "['Category_food', 'Category_shopping', 'paymentMethod_paypal', 'paymentMethod_storecredit', 'isWeekend_1.0', 'numItems', 'localTime', 'paymentMethodAgeDays', 'accountAgeDays']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_food</th>\n",
       "      <th>Category_shopping</th>\n",
       "      <th>paymentMethod_paypal</th>\n",
       "      <th>paymentMethod_storecredit</th>\n",
       "      <th>isWeekend_1.0</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>accountAgeDays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.028772</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.014007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.362181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.421745</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.422211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.345213</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.251126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.682328</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_food  Category_shopping  paymentMethod_paypal  \\\n",
       "0            0.0                1.0                   1.0   \n",
       "1            0.0                0.0                   0.0   \n",
       "2            1.0                0.0                   0.0   \n",
       "3            0.0                0.0                   0.0   \n",
       "4            0.0                1.0                   0.0   \n",
       "\n",
       "   paymentMethod_storecredit  isWeekend_1.0  numItems  localTime  \\\n",
       "0                        0.0            0.0 -0.189142   0.028772   \n",
       "1                        1.0            0.0 -0.189142   0.021742   \n",
       "2                        0.0            1.0 -0.189142   0.421745   \n",
       "3                        0.0            1.0 -0.189142   0.345213   \n",
       "4                        0.0            0.0 -0.189142   0.682328   \n",
       "\n",
       "   paymentMethodAgeDays  accountAgeDays  \n",
       "0              0.557839        0.014007  \n",
       "1             -0.775564        0.362181  \n",
       "2             -0.775564        0.422211  \n",
       "3             -0.775564        0.251126  \n",
       "4             -0.775564        1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_preprocessed_dataframe(preprocessor_obj, X):\n",
    "    \"\"\"\n",
    "    Returns preprocessed dataframe with column names after transformation.\n",
    "    \"\"\"\n",
    "    # Fit and transform\n",
    "    X_transformed = preprocessor_obj.fit_transform(X)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = get_feature_names_from_column_transformer(preprocessor_obj.preprocessor)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    preprocessed_df = pd.DataFrame(X_transformed, columns=feature_names, index=X.index)\n",
    "    \n",
    "    return preprocessed_df\n",
    "\n",
    "\n",
    "# ---------- Usage ----------\n",
    "# Initialize Preprocessing object\n",
    "pre = Preprocessing(\n",
    "    categorical_features=['Category', 'paymentMethod', 'isWeekend'],\n",
    "    skewed_features=['numItems', 'localTime', 'paymentMethodAgeDays'],\n",
    "    symmetric_features=['accountAgeDays'],\n",
    "    steps_to_apply=['preprocessing']  # includes impute, encoding, scaling, log\n",
    ")\n",
    "\n",
    "# Get preprocessed DataFrame\n",
    "preprocessed_df = get_preprocessed_dataframe(pre, X)\n",
    "\n",
    "# Show\n",
    "print(\"Preprocessed columns:\")\n",
    "print(preprocessed_df.columns.tolist())\n",
    "display(preprocessed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebe7a292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineered Columns:\n",
      "['accountAgeDays', 'numItems', 'localTime', 'paymentMethod', 'paymentMethodAgeDays', 'Category', 'isWeekend', 'Category_Payment', 'payment_account_ratio', 'account_age_bin', 'time_of_day']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>Category</th>\n",
       "      <th>isWeekend</th>\n",
       "      <th>Category_Payment</th>\n",
       "      <th>payment_account_ratio</th>\n",
       "      <th>account_age_bin</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>paypal</td>\n",
       "      <td>28.204861</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shopping_paypal</td>\n",
       "      <td>0.940162</td>\n",
       "      <td>new</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>electronics_storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>medium</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>4.921318</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>food</td>\n",
       "      <td>1.0</td>\n",
       "      <td>food_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>old</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>electronics_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>medium</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shopping_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>old</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAgeDays  numItems  localTime paymentMethod  paymentMethodAgeDays  \\\n",
       "0              29         1   4.745402        paypal             28.204861   \n",
       "1             725         1   4.742303   storecredit              0.000000   \n",
       "2             845         1   4.921318    creditcard              0.000000   \n",
       "3             503         1   4.886641    creditcard              0.000000   \n",
       "4            2000         1   5.040929    creditcard              0.000000   \n",
       "\n",
       "      Category  isWeekend         Category_Payment  payment_account_ratio  \\\n",
       "0     shopping        0.0          shopping_paypal               0.940162   \n",
       "1  electronics        0.0  electronics_storecredit               0.000000   \n",
       "2         food        1.0          food_creditcard               0.000000   \n",
       "3  electronics        1.0   electronics_creditcard               0.000000   \n",
       "4     shopping        0.0      shopping_creditcard               0.000000   \n",
       "\n",
       "  account_age_bin time_of_day  \n",
       "0             new       night  \n",
       "1          medium       night  \n",
       "2             old       night  \n",
       "3          medium       night  \n",
       "4             old       night  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed Columns:\n",
      "['Category_food', 'Category_shopping', 'paymentMethod_paypal', 'paymentMethod_storecredit', 'isWeekend_1.0', 'Category_Payment_electronics_paypal', 'Category_Payment_electronics_storecredit', 'Category_Payment_food_creditcard', 'Category_Payment_food_paypal', 'Category_Payment_food_storecredit', 'Category_Payment_shopping_creditcard', 'Category_Payment_shopping_paypal', 'Category_Payment_shopping_storecredit', 'account_age_bin_new', 'account_age_bin_old', 'time_of_day_evening', 'time_of_day_night', 'numItems', 'localTime', 'paymentMethodAgeDays', 'accountAgeDays', 'payment_account_ratio']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_food</th>\n",
       "      <th>Category_shopping</th>\n",
       "      <th>paymentMethod_paypal</th>\n",
       "      <th>paymentMethod_storecredit</th>\n",
       "      <th>isWeekend_1.0</th>\n",
       "      <th>Category_Payment_electronics_paypal</th>\n",
       "      <th>Category_Payment_electronics_storecredit</th>\n",
       "      <th>Category_Payment_food_creditcard</th>\n",
       "      <th>Category_Payment_food_paypal</th>\n",
       "      <th>Category_Payment_food_storecredit</th>\n",
       "      <th>...</th>\n",
       "      <th>Category_Payment_shopping_storecredit</th>\n",
       "      <th>account_age_bin_new</th>\n",
       "      <th>account_age_bin_old</th>\n",
       "      <th>time_of_day_evening</th>\n",
       "      <th>time_of_day_night</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>payment_account_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.028772</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.014007</td>\n",
       "      <td>0.940649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.362181</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.421745</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.422211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.345213</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.251126</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.682328</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_food  Category_shopping  paymentMethod_paypal  \\\n",
       "0            0.0                1.0                   1.0   \n",
       "1            0.0                0.0                   0.0   \n",
       "2            1.0                0.0                   0.0   \n",
       "3            0.0                0.0                   0.0   \n",
       "4            0.0                1.0                   0.0   \n",
       "\n",
       "   paymentMethod_storecredit  isWeekend_1.0  \\\n",
       "0                        0.0            0.0   \n",
       "1                        1.0            0.0   \n",
       "2                        0.0            1.0   \n",
       "3                        0.0            1.0   \n",
       "4                        0.0            0.0   \n",
       "\n",
       "   Category_Payment_electronics_paypal  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   Category_Payment_electronics_storecredit  Category_Payment_food_creditcard  \\\n",
       "0                                       0.0                               0.0   \n",
       "1                                       1.0                               0.0   \n",
       "2                                       0.0                               1.0   \n",
       "3                                       0.0                               0.0   \n",
       "4                                       0.0                               0.0   \n",
       "\n",
       "   Category_Payment_food_paypal  Category_Payment_food_storecredit  ...  \\\n",
       "0                           0.0                                0.0  ...   \n",
       "1                           0.0                                0.0  ...   \n",
       "2                           0.0                                0.0  ...   \n",
       "3                           0.0                                0.0  ...   \n",
       "4                           0.0                                0.0  ...   \n",
       "\n",
       "   Category_Payment_shopping_storecredit  account_age_bin_new  \\\n",
       "0                                    0.0                  1.0   \n",
       "1                                    0.0                  0.0   \n",
       "2                                    0.0                  0.0   \n",
       "3                                    0.0                  0.0   \n",
       "4                                    0.0                  0.0   \n",
       "\n",
       "   account_age_bin_old  time_of_day_evening  time_of_day_night  numItems  \\\n",
       "0                  0.0                  0.0                1.0 -0.189142   \n",
       "1                  0.0                  0.0                1.0 -0.189142   \n",
       "2                  1.0                  0.0                1.0 -0.189142   \n",
       "3                  0.0                  0.0                1.0 -0.189142   \n",
       "4                  1.0                  0.0                1.0 -0.189142   \n",
       "\n",
       "   localTime  paymentMethodAgeDays  accountAgeDays  payment_account_ratio  \n",
       "0   0.028772              0.557839        0.014007               0.940649  \n",
       "1   0.021742             -0.775564        0.362181               0.000000  \n",
       "2   0.421745             -0.775564        0.422211               0.000000  \n",
       "3   0.345213             -0.775564        0.251126               0.000000  \n",
       "4   0.682328             -0.775564        1.000000               0.000000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize FeatureEngineering with chosen steps\n",
    "fe = FeatureEngineering(\n",
    "    steps_to_apply=['feature_engineering', 'interaction', 'ratio', 'binning', 'time_feature']\n",
    ")\n",
    "\n",
    "# Apply feature engineering\n",
    "X_fe = fe.fit_transform(X)\n",
    "\n",
    "print(\"Feature Engineered Columns:\")\n",
    "print(X_fe.columns.tolist())\n",
    "display(X_fe.head())\n",
    "\n",
    "# Initialize Preprocessing with chosen steps\n",
    "pre = Preprocessing(\n",
    "    categorical_features=['Category', 'paymentMethod', 'isWeekend', 'Category_Payment', 'account_age_bin', 'time_of_day'],\n",
    "    skewed_features=['numItems', 'localTime', 'paymentMethodAgeDays'],\n",
    "    symmetric_features=['accountAgeDays', 'payment_account_ratio'],\n",
    "    steps_to_apply=['preprocessing']  # includes impute, encoding, log, scaling\n",
    ")\n",
    "\n",
    "# Fit & transform feature engineered data\n",
    "X_preprocessed = pre.fit_transform(X_fe)\n",
    "\n",
    "# Extract transformed feature names\n",
    "feature_names = get_feature_names_from_column_transformer(pre.preprocessor)\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=feature_names, index=X_fe.index)\n",
    "\n",
    "print(\"\\nPreprocessed Columns:\")\n",
    "print(X_preprocessed_df.columns.tolist())\n",
    "display(X_preprocessed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bdde09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
